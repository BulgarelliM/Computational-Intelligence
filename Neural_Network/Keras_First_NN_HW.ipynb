{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set (Internet Access needed)\n",
    "\n",
    "##url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('pima-indians-diabetes.data', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>8</td>\n",
       "      <td>120</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.259</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>70</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.147</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>37.3</td>\n",
       "      <td>0.238</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>68</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0.745</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "731               8                     120              86               0   \n",
       "643               4                      90               0               0   \n",
       "438               1                      97              70              15   \n",
       "504               3                      96              78              39   \n",
       "185               7                     194              68              28   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "731        0  28.4              0.259   22             1  \n",
       "643        0  28.0              0.610   31             0  \n",
       "438        0  18.2              0.147   21             0  \n",
       "504        0  37.3              0.238   40             0  \n",
       "185        0  35.9              0.745   41             1  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.771\n",
      "roc-auc is 0.834\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "#O método \"predict_classes\" não funciona nas versões do Keras superior a 2.5 \n",
    "\n",
    "# A indicação da correção se encontra em https://keras.rstudio.com/reference/predict_proba.html#details. \n",
    "\n",
    "# usar: \n",
    "# y_pred_class_nn_1 = model_1.predict(X_test_norm)\n",
    "# y_pred_class_nn_1 = (y_pred_prob_nn_1 > 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 12)                108       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(model_1.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">---------------------------------------------------------------------------------------------</span>\n",
    "#### <span style=\"color:red\">RESPOSTA</span>\n",
    "Cada linha representa um layer adicionado. Cada camada tem um output e sua forma é mostrada na coluna “Output Shape”. \n",
    "\n",
    "Temos 121 parâmetros pois a saída de cada camada torna-se a entrada para a camada subsequente e este valor é multiplicado pelo input acrescido de 1.\n",
    "\n",
    "param_number = output_channel_number * (input_channel_number + 1)\n",
    "\n",
    "12*(8+1)=108\n",
    "1*(12+1)=13\n",
    "\n",
    "\n",
    "Fonte: https://towardsdatascience.com/how-to-calculate-the-number-of-parameters-in-keras-models-710683dae0ca\n",
    "\n",
    "<span style=\"color:red\">---------------------------------------------------------------------------------------------</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 9ms/step - loss: 0.8733 - accuracy: 0.4479 - val_loss: 0.8675 - val_accuracy: 0.4531\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8628 - accuracy: 0.4549 - val_loss: 0.8569 - val_accuracy: 0.4583\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8528 - accuracy: 0.4531 - val_loss: 0.8467 - val_accuracy: 0.4531\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8432 - accuracy: 0.4549 - val_loss: 0.8371 - val_accuracy: 0.4740\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8341 - accuracy: 0.4670 - val_loss: 0.8278 - val_accuracy: 0.4740\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8254 - accuracy: 0.4705 - val_loss: 0.8189 - val_accuracy: 0.4740\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8170 - accuracy: 0.4792 - val_loss: 0.8103 - val_accuracy: 0.4792\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8090 - accuracy: 0.4809 - val_loss: 0.8020 - val_accuracy: 0.4844\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.8013 - accuracy: 0.4809 - val_loss: 0.7941 - val_accuracy: 0.4844\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7939 - accuracy: 0.4861 - val_loss: 0.7864 - val_accuracy: 0.4948\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7866 - accuracy: 0.4896 - val_loss: 0.7791 - val_accuracy: 0.5052\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7796 - accuracy: 0.4931 - val_loss: 0.7720 - val_accuracy: 0.5156\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7728 - accuracy: 0.4965 - val_loss: 0.7652 - val_accuracy: 0.5156\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7662 - accuracy: 0.5000 - val_loss: 0.7586 - val_accuracy: 0.5417\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7600 - accuracy: 0.5069 - val_loss: 0.7523 - val_accuracy: 0.5521\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7539 - accuracy: 0.5156 - val_loss: 0.7462 - val_accuracy: 0.5469\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7480 - accuracy: 0.5278 - val_loss: 0.7403 - val_accuracy: 0.5625\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.5330 - val_loss: 0.7346 - val_accuracy: 0.5729\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.5417 - val_loss: 0.7291 - val_accuracy: 0.5781\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7313 - accuracy: 0.5434 - val_loss: 0.7238 - val_accuracy: 0.5833\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7261 - accuracy: 0.5434 - val_loss: 0.7186 - val_accuracy: 0.5885\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7209 - accuracy: 0.5486 - val_loss: 0.7136 - val_accuracy: 0.5990\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7159 - accuracy: 0.5642 - val_loss: 0.7087 - val_accuracy: 0.6042\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7110 - accuracy: 0.5764 - val_loss: 0.7039 - val_accuracy: 0.6094\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7062 - accuracy: 0.5781 - val_loss: 0.6993 - val_accuracy: 0.6146\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7016 - accuracy: 0.5833 - val_loss: 0.6949 - val_accuracy: 0.6146\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.5885 - val_loss: 0.6906 - val_accuracy: 0.6094\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5938 - val_loss: 0.6864 - val_accuracy: 0.6094\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.6007 - val_loss: 0.6823 - val_accuracy: 0.6146\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.6042 - val_loss: 0.6784 - val_accuracy: 0.6198\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.6059 - val_loss: 0.6745 - val_accuracy: 0.6250\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.6146 - val_loss: 0.6708 - val_accuracy: 0.6250\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6720 - accuracy: 0.6181 - val_loss: 0.6671 - val_accuracy: 0.6354\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.6198 - val_loss: 0.6635 - val_accuracy: 0.6354\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.6198 - val_loss: 0.6600 - val_accuracy: 0.6354\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.6250 - val_loss: 0.6565 - val_accuracy: 0.6354\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.6233 - val_loss: 0.6532 - val_accuracy: 0.6406\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6233 - val_loss: 0.6499 - val_accuracy: 0.6510\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6250 - val_loss: 0.6467 - val_accuracy: 0.6406\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.6354 - val_loss: 0.6435 - val_accuracy: 0.6458\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.6389 - val_loss: 0.6405 - val_accuracy: 0.6458\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.6424 - val_loss: 0.6375 - val_accuracy: 0.6458\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.6528 - val_loss: 0.6345 - val_accuracy: 0.6510\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.6597 - val_loss: 0.6317 - val_accuracy: 0.6510\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.6615 - val_loss: 0.6290 - val_accuracy: 0.6562\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6615 - val_loss: 0.6263 - val_accuracy: 0.6667\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6684 - val_loss: 0.6237 - val_accuracy: 0.6875\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.6684 - val_loss: 0.6212 - val_accuracy: 0.6979\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.6719 - val_loss: 0.6187 - val_accuracy: 0.6927\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6701 - val_loss: 0.6163 - val_accuracy: 0.6927\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6149 - accuracy: 0.6632 - val_loss: 0.6139 - val_accuracy: 0.6979\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6632 - val_loss: 0.6116 - val_accuracy: 0.6979\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.6615 - val_loss: 0.6093 - val_accuracy: 0.7031\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.6597 - val_loss: 0.6070 - val_accuracy: 0.7031\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.6597 - val_loss: 0.6048 - val_accuracy: 0.7083\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.6667 - val_loss: 0.6027 - val_accuracy: 0.7083\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.6667 - val_loss: 0.6006 - val_accuracy: 0.7135\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.6701 - val_loss: 0.5986 - val_accuracy: 0.7135\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.6719 - val_loss: 0.5966 - val_accuracy: 0.7083\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.6719 - val_loss: 0.5946 - val_accuracy: 0.7083\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.6753 - val_loss: 0.5927 - val_accuracy: 0.7083\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.6788 - val_loss: 0.5908 - val_accuracy: 0.7083\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.6788 - val_loss: 0.5890 - val_accuracy: 0.7083\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5868 - accuracy: 0.6823 - val_loss: 0.5872 - val_accuracy: 0.6979\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.6840 - val_loss: 0.5854 - val_accuracy: 0.7031\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.6858 - val_loss: 0.5837 - val_accuracy: 0.7031\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.6840 - val_loss: 0.5820 - val_accuracy: 0.7031\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.6858 - val_loss: 0.5804 - val_accuracy: 0.7083\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.6875 - val_loss: 0.5788 - val_accuracy: 0.7083\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.6892 - val_loss: 0.5772 - val_accuracy: 0.7135\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5747 - accuracy: 0.6892 - val_loss: 0.5757 - val_accuracy: 0.7135\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5731 - accuracy: 0.6892 - val_loss: 0.5742 - val_accuracy: 0.7135\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.6927 - val_loss: 0.5727 - val_accuracy: 0.7083\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.6927 - val_loss: 0.5713 - val_accuracy: 0.7083\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.6944 - val_loss: 0.5699 - val_accuracy: 0.7083\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.6962 - val_loss: 0.5685 - val_accuracy: 0.7135\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.6979 - val_loss: 0.5671 - val_accuracy: 0.7135\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.6997 - val_loss: 0.5657 - val_accuracy: 0.7135\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5625 - accuracy: 0.7049 - val_loss: 0.5644 - val_accuracy: 0.7135\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7049 - val_loss: 0.5631 - val_accuracy: 0.7083\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7049 - val_loss: 0.5618 - val_accuracy: 0.7031\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7049 - val_loss: 0.5605 - val_accuracy: 0.7031\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7049 - val_loss: 0.5593 - val_accuracy: 0.7031\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7049 - val_loss: 0.5580 - val_accuracy: 0.6979\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7083 - val_loss: 0.5568 - val_accuracy: 0.6979\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.7066 - val_loss: 0.5556 - val_accuracy: 0.7031\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7066 - val_loss: 0.5545 - val_accuracy: 0.7031\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7066 - val_loss: 0.5533 - val_accuracy: 0.7031\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7083 - val_loss: 0.5522 - val_accuracy: 0.7083\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7083 - val_loss: 0.5511 - val_accuracy: 0.7083\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7066 - val_loss: 0.5500 - val_accuracy: 0.7083\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7101 - val_loss: 0.5490 - val_accuracy: 0.7083\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7083 - val_loss: 0.5479 - val_accuracy: 0.7083\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7083 - val_loss: 0.5469 - val_accuracy: 0.7083\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7083 - val_loss: 0.5459 - val_accuracy: 0.7135\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7118 - val_loss: 0.5449 - val_accuracy: 0.7135\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7083 - val_loss: 0.5439 - val_accuracy: 0.7083\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7083 - val_loss: 0.5429 - val_accuracy: 0.7083\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7135 - val_loss: 0.5420 - val_accuracy: 0.7135\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7153 - val_loss: 0.5410 - val_accuracy: 0.7135\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7153 - val_loss: 0.5401 - val_accuracy: 0.7135\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7153 - val_loss: 0.5392 - val_accuracy: 0.7135\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7170 - val_loss: 0.5383 - val_accuracy: 0.7083\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7222 - val_loss: 0.5375 - val_accuracy: 0.7135\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7240 - val_loss: 0.5366 - val_accuracy: 0.7135\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7240 - val_loss: 0.5358 - val_accuracy: 0.7135\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7240 - val_loss: 0.5349 - val_accuracy: 0.7240\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.7240 - val_loss: 0.5341 - val_accuracy: 0.7240\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7240 - val_loss: 0.5333 - val_accuracy: 0.7240\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7240 - val_loss: 0.5325 - val_accuracy: 0.7240\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7257 - val_loss: 0.5317 - val_accuracy: 0.7240\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7257 - val_loss: 0.5309 - val_accuracy: 0.7240\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7240 - val_loss: 0.5302 - val_accuracy: 0.7240\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7257 - val_loss: 0.5294 - val_accuracy: 0.7188\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7257 - val_loss: 0.5287 - val_accuracy: 0.7240\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7309 - val_loss: 0.5280 - val_accuracy: 0.7240\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7326 - val_loss: 0.5273 - val_accuracy: 0.7240\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7326 - val_loss: 0.5267 - val_accuracy: 0.7240\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7326 - val_loss: 0.5260 - val_accuracy: 0.7240\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7326 - val_loss: 0.5254 - val_accuracy: 0.7240\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5188 - accuracy: 0.7326 - val_loss: 0.5247 - val_accuracy: 0.7240\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5180 - accuracy: 0.7326 - val_loss: 0.5241 - val_accuracy: 0.7240\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.7344 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7326 - val_loss: 0.5229 - val_accuracy: 0.7240\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7361 - val_loss: 0.5223 - val_accuracy: 0.7240\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5151 - accuracy: 0.7361 - val_loss: 0.5218 - val_accuracy: 0.7240\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7361 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7361 - val_loss: 0.5206 - val_accuracy: 0.7240\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.7361 - val_loss: 0.5201 - val_accuracy: 0.7240\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7361 - val_loss: 0.5195 - val_accuracy: 0.7240\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7396 - val_loss: 0.5190 - val_accuracy: 0.7240\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7396 - val_loss: 0.5184 - val_accuracy: 0.7240\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7378 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7378 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7396 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7361 - val_loss: 0.5164 - val_accuracy: 0.7344\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7378 - val_loss: 0.5159 - val_accuracy: 0.7396\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7396 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7413 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7413 - val_loss: 0.5145 - val_accuracy: 0.7396\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7413 - val_loss: 0.5141 - val_accuracy: 0.7396\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7413 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7413 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7413 - val_loss: 0.5127 - val_accuracy: 0.7396\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7413 - val_loss: 0.5123 - val_accuracy: 0.7448\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7413 - val_loss: 0.5119 - val_accuracy: 0.7448\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7396 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7413 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7396 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7413 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7431 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.7413 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7413 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7413 - val_loss: 0.5089 - val_accuracy: 0.7500\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7413 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7413 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7413 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7431 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7431 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7448 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7448 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.7465 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7465 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7465 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7465 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7483 - val_loss: 0.5051 - val_accuracy: 0.7396\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.7500 - val_loss: 0.5049 - val_accuracy: 0.7396\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7500 - val_loss: 0.5046 - val_accuracy: 0.7396\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7500 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7500 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7500 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7500 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7500 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7483 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7483 - val_loss: 0.5028 - val_accuracy: 0.7500\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7483 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7500 - val_loss: 0.5024 - val_accuracy: 0.7500\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7517 - val_loss: 0.5022 - val_accuracy: 0.7500\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.7517 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7517 - val_loss: 0.5017 - val_accuracy: 0.7500\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7500 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7483 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7483 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7483 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7483 - val_loss: 0.5008 - val_accuracy: 0.7500\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7483 - val_loss: 0.5006 - val_accuracy: 0.7552\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7483 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7483 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7483 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4845 - accuracy: 0.7465 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7465 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7465 - val_loss: 0.4995 - val_accuracy: 0.7552\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7465 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4098 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4832 - accuracy: 0.7483 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7500 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7517 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7535 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7500 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7517 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7535 - val_loss: 0.4983 - val_accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "#y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "#y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "y_pred_class_nn_1 = (y_pred_prob_nn_1 > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46187657],\n",
       "       [0.6460588 ],\n",
       "       [0.36901093],\n",
       "       [0.37831712],\n",
       "       [0.221023  ],\n",
       "       [0.3601045 ],\n",
       "       [0.05445614],\n",
       "       [0.40440658],\n",
       "       [0.7543483 ],\n",
       "       [0.20483997]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.755\n",
      "roc-auc is 0.816\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21bddac3f10>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4809 - accuracy: 0.7517 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7517 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7483 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7500 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7535 - val_loss: 0.4976 - val_accuracy: 0.7552\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7535 - val_loss: 0.4974 - val_accuracy: 0.7552\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7535 - val_loss: 0.4973 - val_accuracy: 0.7552\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7535 - val_loss: 0.4972 - val_accuracy: 0.7552\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7517 - val_loss: 0.4970 - val_accuracy: 0.7552\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7517 - val_loss: 0.4969 - val_accuracy: 0.7552\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7517 - val_loss: 0.4968 - val_accuracy: 0.7552\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7517 - val_loss: 0.4966 - val_accuracy: 0.7552\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7517 - val_loss: 0.4965 - val_accuracy: 0.7552\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7517 - val_loss: 0.4964 - val_accuracy: 0.7604\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7517 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7517 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7517 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7517 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7517 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7517 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7517 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7535 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7569 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7587 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7569 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7587 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7587 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7569 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7587 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7587 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7587 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7587 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7569 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7604 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7587 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7587 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7569 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7587 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7587 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7587 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7587 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7587 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7569 - val_loss: 0.4937 - val_accuracy: 0.7604\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7622 - val_loss: 0.4936 - val_accuracy: 0.7604\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7639 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7639 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7639 - val_loss: 0.4934 - val_accuracy: 0.7604\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7622 - val_loss: 0.4934 - val_accuracy: 0.7604\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7622 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7639 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7639 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7639 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7639 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7639 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7639 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7656 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7656 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7656 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7656 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7656 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7656 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7656 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7656 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7656 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7656 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7656 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7639 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7639 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7656 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7656 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7639 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7622 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7622 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7622 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7604 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7604 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7622 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7604 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7622 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7604 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7587 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7587 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7587 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7587 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7604 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7604 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7604 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7604 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7604 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7604 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7604 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7622 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7604 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7622 - val_loss: 0.4919 - val_accuracy: 0.7604\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7622 - val_loss: 0.4919 - val_accuracy: 0.7604\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7622 - val_loss: 0.4919 - val_accuracy: 0.7604\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7622 - val_loss: 0.4919 - val_accuracy: 0.7604\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7622 - val_loss: 0.4919 - val_accuracy: 0.7604\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7622 - val_loss: 0.4919 - val_accuracy: 0.7604\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7622 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7622 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7604 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7604 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7604 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7604 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7622 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7622 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7639 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7622 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7639 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7622 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7639 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7639 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7639 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7639 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7639 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7639 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7639 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7639 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7639 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7639 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7639 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7639 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7639 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7639 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7639 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7639 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7639 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7656 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7674 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7674 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7708 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4514 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4513 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7656\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7760 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7656\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7656\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7743 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7760 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.7743 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7760 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7760 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7743 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7760 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7656\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7743 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7760 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7760 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7760 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7760 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7760 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7760 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7760 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7760 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7760 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7760 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7760 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7760 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7760 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7760 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7760 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7760 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7760 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7760 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7760 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4382 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7812 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7795 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7795 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7795 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7795 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7795 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7795 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7830 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7795 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7795 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7778 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7795 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7778 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7778 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7795 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7778 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7778 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7795 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7795 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7795 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7795 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7795 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3612 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7795 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7795 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7795 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7778 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7795 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7778 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7795 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7795 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7795 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7795 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7778 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7795 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7812 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7795 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7778 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7795 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7795 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7795 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7795 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7795 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7778 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7795 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7795 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7795 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7778 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.7795 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7795 - val_loss: 0.4939 - val_accuracy: 0.7812\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7778 - val_loss: 0.4939 - val_accuracy: 0.7812\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7812 - val_loss: 0.4939 - val_accuracy: 0.7812\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7795 - val_loss: 0.4939 - val_accuracy: 0.7812\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7830 - val_loss: 0.4939 - val_accuracy: 0.7812\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7812 - val_loss: 0.4940 - val_accuracy: 0.7812\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7830 - val_loss: 0.4940 - val_accuracy: 0.7812\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7795 - val_loss: 0.4940 - val_accuracy: 0.7812\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7812 - val_loss: 0.4940 - val_accuracy: 0.7812\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7830 - val_loss: 0.4941 - val_accuracy: 0.7812\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7830 - val_loss: 0.4941 - val_accuracy: 0.7812\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7812\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7812\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7812 - val_loss: 0.4941 - val_accuracy: 0.7812\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7812 - val_loss: 0.4942 - val_accuracy: 0.7812\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7812 - val_loss: 0.4942 - val_accuracy: 0.7812\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.4942 - val_accuracy: 0.7812\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7812 - val_loss: 0.4942 - val_accuracy: 0.7812\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4942 - val_accuracy: 0.7812\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7830 - val_loss: 0.4943 - val_accuracy: 0.7812\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7812 - val_loss: 0.4943 - val_accuracy: 0.7812\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7812 - val_loss: 0.4943 - val_accuracy: 0.7812\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4943 - val_accuracy: 0.7812\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7812 - val_loss: 0.4943 - val_accuracy: 0.7865\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7865 - val_loss: 0.4944 - val_accuracy: 0.7865\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7830 - val_loss: 0.4944 - val_accuracy: 0.7865\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7882 - val_loss: 0.4944 - val_accuracy: 0.7865\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.4944 - val_accuracy: 0.7865\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7865 - val_loss: 0.4944 - val_accuracy: 0.7865\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7865 - val_loss: 0.4945 - val_accuracy: 0.7865\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.4945 - val_accuracy: 0.7865\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7830 - val_loss: 0.4945 - val_accuracy: 0.7865\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.4945 - val_accuracy: 0.7865\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.4945 - val_accuracy: 0.7865\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7830 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.7830 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7830 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7830 - val_loss: 0.4946 - val_accuracy: 0.7865\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7830 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7830 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7812 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7830 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7812 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7830 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7830 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7830 - val_loss: 0.4947 - val_accuracy: 0.7865\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7830 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.4948 - val_accuracy: 0.7865\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7830 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7830 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7812 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7830 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7830 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7830 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7830 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7830 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7812 - val_loss: 0.4949 - val_accuracy: 0.7865\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.4950 - val_accuracy: 0.7865\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.4950 - val_accuracy: 0.7865\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7830 - val_loss: 0.4950 - val_accuracy: 0.7865\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.4950 - val_accuracy: 0.7865\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7812 - val_loss: 0.4950 - val_accuracy: 0.7865\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.4950 - val_accuracy: 0.7865\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7830 - val_loss: 0.4950 - val_accuracy: 0.7865\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.4950 - val_accuracy: 0.7865\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.4950 - val_accuracy: 0.7865\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7830 - val_loss: 0.4950 - val_accuracy: 0.7865\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7830 - val_loss: 0.4951 - val_accuracy: 0.7865\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7847 - val_loss: 0.4951 - val_accuracy: 0.7865\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7830 - val_loss: 0.4951 - val_accuracy: 0.7865\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7830 - val_loss: 0.4951 - val_accuracy: 0.7865\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7830 - val_loss: 0.4951 - val_accuracy: 0.7865\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7830 - val_loss: 0.4951 - val_accuracy: 0.7865\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7847 - val_loss: 0.4951 - val_accuracy: 0.7865\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.4951 - val_accuracy: 0.7865\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7830 - val_loss: 0.4951 - val_accuracy: 0.7865\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7847 - val_loss: 0.4951 - val_accuracy: 0.7865\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.4951 - val_accuracy: 0.7865\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7830 - val_loss: 0.4951 - val_accuracy: 0.7865\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7847 - val_loss: 0.4952 - val_accuracy: 0.7865\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.4952 - val_accuracy: 0.7865\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7847 - val_loss: 0.4952 - val_accuracy: 0.7865\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7830 - val_loss: 0.4952 - val_accuracy: 0.7865\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.4952 - val_accuracy: 0.7865\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7847 - val_loss: 0.4952 - val_accuracy: 0.7865\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7847 - val_loss: 0.4952 - val_accuracy: 0.7865\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7847 - val_loss: 0.4952 - val_accuracy: 0.7865\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7847 - val_loss: 0.4952 - val_accuracy: 0.7865\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7847 - val_loss: 0.4953 - val_accuracy: 0.7865\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7847 - val_loss: 0.4953 - val_accuracy: 0.7865\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7847 - val_loss: 0.4953 - val_accuracy: 0.7865\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.4953 - val_accuracy: 0.7865\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7847 - val_loss: 0.4953 - val_accuracy: 0.7865\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7847 - val_loss: 0.4953 - val_accuracy: 0.7865\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7847 - val_loss: 0.4953 - val_accuracy: 0.7865\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7847 - val_loss: 0.4953 - val_accuracy: 0.7865\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7847 - val_loss: 0.4953 - val_accuracy: 0.7865\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7847 - val_loss: 0.4953 - val_accuracy: 0.7865\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7847 - val_loss: 0.4953 - val_accuracy: 0.7865\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7847 - val_loss: 0.4953 - val_accuracy: 0.7865\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7865\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7865\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7865\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7865\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7865\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.4954 - val_accuracy: 0.7865\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4282 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7865\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7865\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7865\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7865\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7865\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7865\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7847 - val_loss: 0.4954 - val_accuracy: 0.7865\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7865\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7865 - val_loss: 0.4955 - val_accuracy: 0.7865\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7865\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7865\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7865\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7865\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7865\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7865\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7865\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7865\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7865\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7865\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7847 - val_loss: 0.4955 - val_accuracy: 0.7865\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7847 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7847 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7847 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7847 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7865 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7847 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7865 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7847 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7847 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.4956 - val_accuracy: 0.7865\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.7847 - val_loss: 0.4957 - val_accuracy: 0.7865\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.4957 - val_accuracy: 0.7865\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7847 - val_loss: 0.4957 - val_accuracy: 0.7865\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7847 - val_loss: 0.4957 - val_accuracy: 0.7865\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7865 - val_loss: 0.4957 - val_accuracy: 0.7865\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.4957 - val_accuracy: 0.7865\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7865 - val_loss: 0.4957 - val_accuracy: 0.7865\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7865 - val_loss: 0.4957 - val_accuracy: 0.7865\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.4957 - val_accuracy: 0.7865\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.4957 - val_accuracy: 0.7865\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.4958 - val_accuracy: 0.7865\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.4958 - val_accuracy: 0.7865\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.4958 - val_accuracy: 0.7865\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.4958 - val_accuracy: 0.7865\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.4958 - val_accuracy: 0.7865\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7882 - val_loss: 0.4958 - val_accuracy: 0.7865\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7882 - val_loss: 0.4959 - val_accuracy: 0.7865\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7865 - val_loss: 0.4959 - val_accuracy: 0.7865\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7882 - val_loss: 0.4959 - val_accuracy: 0.7865\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.4959 - val_accuracy: 0.7865\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7882 - val_loss: 0.4959 - val_accuracy: 0.7865\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7865 - val_loss: 0.4959 - val_accuracy: 0.7865\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7865 - val_loss: 0.4959 - val_accuracy: 0.7865\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.4959 - val_accuracy: 0.7865\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.4960 - val_accuracy: 0.7865\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.4960 - val_accuracy: 0.7865\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7882 - val_loss: 0.4960 - val_accuracy: 0.7865\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7865 - val_loss: 0.4960 - val_accuracy: 0.7865\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7865 - val_loss: 0.4960 - val_accuracy: 0.7865\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7882 - val_loss: 0.4960 - val_accuracy: 0.7865\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7865 - val_loss: 0.4960 - val_accuracy: 0.7865\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.4961 - val_accuracy: 0.7865\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7899 - val_loss: 0.4961 - val_accuracy: 0.7865\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.4961 - val_accuracy: 0.7865\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.4961 - val_accuracy: 0.7865\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.4961 - val_accuracy: 0.7865\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7882 - val_loss: 0.4961 - val_accuracy: 0.7865\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7899 - val_loss: 0.4961 - val_accuracy: 0.7865\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.4961 - val_accuracy: 0.7865\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.4962 - val_accuracy: 0.7865\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4802 - accuracy: 0.81 - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7899 - val_loss: 0.4962 - val_accuracy: 0.7865\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7899 - val_loss: 0.4962 - val_accuracy: 0.7865\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.4962 - val_accuracy: 0.7865\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4261 - accuracy: 0.7882 - val_loss: 0.4962 - val_accuracy: 0.7865\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7882 - val_loss: 0.4962 - val_accuracy: 0.7865\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.4962 - val_accuracy: 0.7865\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7882 - val_loss: 0.4962 - val_accuracy: 0.7865\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.4963 - val_accuracy: 0.7865\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7899 - val_loss: 0.4963 - val_accuracy: 0.7865\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.4963 - val_accuracy: 0.7865\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7882 - val_loss: 0.4963 - val_accuracy: 0.7865\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7882 - val_loss: 0.4963 - val_accuracy: 0.7865\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7882 - val_loss: 0.4963 - val_accuracy: 0.7917\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7882 - val_loss: 0.4963 - val_accuracy: 0.7917\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7882 - val_loss: 0.4963 - val_accuracy: 0.7969\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7882 - val_loss: 0.4964 - val_accuracy: 0.7969\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.4964 - val_accuracy: 0.7969\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.4964 - val_accuracy: 0.7969\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.4964 - val_accuracy: 0.7969\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.4964 - val_accuracy: 0.7969\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7882 - val_loss: 0.4964 - val_accuracy: 0.7969\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.4965 - val_accuracy: 0.7969\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7882 - val_loss: 0.4965 - val_accuracy: 0.7969\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7882 - val_loss: 0.4965 - val_accuracy: 0.7969\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7882 - val_loss: 0.4965 - val_accuracy: 0.7969\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4255 - accuracy: 0.7882 - val_loss: 0.4965 - val_accuracy: 0.7969\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.4965 - val_accuracy: 0.7969\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7882 - val_loss: 0.4965 - val_accuracy: 0.7969\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7882 - val_loss: 0.4966 - val_accuracy: 0.7969\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.7882 - val_loss: 0.4966 - val_accuracy: 0.7969\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7882 - val_loss: 0.4966 - val_accuracy: 0.7969\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7882 - val_loss: 0.4966 - val_accuracy: 0.7969\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7882 - val_loss: 0.4966 - val_accuracy: 0.7969\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7882 - val_loss: 0.4966 - val_accuracy: 0.7969\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.4966 - val_accuracy: 0.7969\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.7882 - val_loss: 0.4966 - val_accuracy: 0.7969\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.4966 - val_accuracy: 0.7969\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.4966 - val_accuracy: 0.7969\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.4967 - val_accuracy: 0.7969\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.4967 - val_accuracy: 0.7969\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.4967 - val_accuracy: 0.7969\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.4967 - val_accuracy: 0.7969\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.4967 - val_accuracy: 0.7969\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.4967 - val_accuracy: 0.7969\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.4967 - val_accuracy: 0.7969\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7882 - val_loss: 0.4967 - val_accuracy: 0.7969\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7969\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7969\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7969\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7969\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7969\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7969\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7969\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7969\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7969\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.4968 - val_accuracy: 0.7969\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.4969 - val_accuracy: 0.7969\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.4969 - val_accuracy: 0.7969\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.4969 - val_accuracy: 0.7969\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.4969 - val_accuracy: 0.7969\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.4969 - val_accuracy: 0.7969\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.4969 - val_accuracy: 0.7969\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.4969 - val_accuracy: 0.7969\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.4970 - val_accuracy: 0.7969\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.4970 - val_accuracy: 0.7969\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.4970 - val_accuracy: 0.7969\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.4970 - val_accuracy: 0.7969\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.4970 - val_accuracy: 0.7969\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.4970 - val_accuracy: 0.7969\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.4970 - val_accuracy: 0.7969\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.4971 - val_accuracy: 0.7969\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.4971 - val_accuracy: 0.7969\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.4971 - val_accuracy: 0.7969\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.4971 - val_accuracy: 0.7969\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.4971 - val_accuracy: 0.7969\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.4971 - val_accuracy: 0.7969\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.4971 - val_accuracy: 0.7969\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.4972 - val_accuracy: 0.7969\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.4972 - val_accuracy: 0.7969\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4242 - accuracy: 0.7917 - val_loss: 0.4972 - val_accuracy: 0.7969\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7917 - val_loss: 0.4972 - val_accuracy: 0.7969\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.4972 - val_accuracy: 0.7969\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7969\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7969\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7969\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7969\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7969\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7969\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.4974 - val_accuracy: 0.7969\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.4974 - val_accuracy: 0.7969\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7917 - val_loss: 0.4974 - val_accuracy: 0.7969\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.4974 - val_accuracy: 0.7969\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.4975 - val_accuracy: 0.7969\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.4975 - val_accuracy: 0.7969\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.4975 - val_accuracy: 0.7969\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.4975 - val_accuracy: 0.7969\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.4976 - val_accuracy: 0.7969\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.4976 - val_accuracy: 0.7969\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.4976 - val_accuracy: 0.7969\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.4976 - val_accuracy: 0.7969\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.4976 - val_accuracy: 0.7969\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.7917 - val_loss: 0.4977 - val_accuracy: 0.7969\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7917 - val_loss: 0.4977 - val_accuracy: 0.7969\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7917 - val_loss: 0.4977 - val_accuracy: 0.7969\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7917 - val_loss: 0.4977 - val_accuracy: 0.7969\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.4977 - val_accuracy: 0.7969\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7969\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.4978 - val_accuracy: 0.7969\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.4978 - val_accuracy: 0.7969\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7934 - val_loss: 0.4978 - val_accuracy: 0.7969\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7934 - val_loss: 0.4979 - val_accuracy: 0.7969\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7934 - val_loss: 0.4979 - val_accuracy: 0.7969\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7934 - val_loss: 0.4979 - val_accuracy: 0.7969\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.7934 - val_loss: 0.4979 - val_accuracy: 0.7969\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7934 - val_loss: 0.4979 - val_accuracy: 0.7969\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7934 - val_loss: 0.4980 - val_accuracy: 0.7969\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7934 - val_loss: 0.4980 - val_accuracy: 0.7969\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.7934 - val_loss: 0.4980 - val_accuracy: 0.7969\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4231 - accuracy: 0.7951 - val_loss: 0.4980 - val_accuracy: 0.7969\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.7934 - val_loss: 0.4980 - val_accuracy: 0.7969\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7951 - val_loss: 0.4981 - val_accuracy: 0.7969\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7934 - val_loss: 0.4981 - val_accuracy: 0.7917\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7934 - val_loss: 0.4981 - val_accuracy: 0.7917\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.4981 - val_accuracy: 0.7917\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7934 - val_loss: 0.4981 - val_accuracy: 0.7917\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.4981 - val_accuracy: 0.7917\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.4982 - val_accuracy: 0.7917\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.4982 - val_accuracy: 0.7917\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.4982 - val_accuracy: 0.7917\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.4982 - val_accuracy: 0.7917\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.4982 - val_accuracy: 0.7917\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7934 - val_loss: 0.4982 - val_accuracy: 0.7917\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7934 - val_loss: 0.4982 - val_accuracy: 0.7917\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.4983 - val_accuracy: 0.7917\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7934 - val_loss: 0.4983 - val_accuracy: 0.7917\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.4983 - val_accuracy: 0.7917\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.4983 - val_accuracy: 0.7917\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.4983 - val_accuracy: 0.7917\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7934 - val_loss: 0.4984 - val_accuracy: 0.7917\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.4984 - val_accuracy: 0.7917\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.4984 - val_accuracy: 0.7917\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.4984 - val_accuracy: 0.7917\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.4984 - val_accuracy: 0.7917\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.4984 - val_accuracy: 0.7917\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.4984 - val_accuracy: 0.7917\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.4984 - val_accuracy: 0.7917\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.4985 - val_accuracy: 0.7917\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.4985 - val_accuracy: 0.7969\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.4985 - val_accuracy: 0.7969\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.4985 - val_accuracy: 0.7969\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.4985 - val_accuracy: 0.7969\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.4985 - val_accuracy: 0.7969\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.4986 - val_accuracy: 0.7969\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.4986 - val_accuracy: 0.7969\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.4986 - val_accuracy: 0.7969\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.4986 - val_accuracy: 0.7969\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.4986 - val_accuracy: 0.7969\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.4986 - val_accuracy: 0.7969\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7969\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7969\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7969\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7969\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.4987 - val_accuracy: 0.7969\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7969\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.4987 - val_accuracy: 0.7969\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4988 - val_accuracy: 0.7969\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4988 - val_accuracy: 0.7969\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4988 - val_accuracy: 0.7969\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.4988 - val_accuracy: 0.7969\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.4988 - val_accuracy: 0.7969\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.4988 - val_accuracy: 0.7969\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7969 - val_loss: 0.4989 - val_accuracy: 0.7969\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.4989 - val_accuracy: 0.7969\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.4989 - val_accuracy: 0.7969\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.4989 - val_accuracy: 0.7969\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.4989 - val_accuracy: 0.7969\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.4989 - val_accuracy: 0.7969\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7969 - val_loss: 0.4990 - val_accuracy: 0.7969\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.4990 - val_accuracy: 0.7969\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.4990 - val_accuracy: 0.7969\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7969 - val_loss: 0.4990 - val_accuracy: 0.7969\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7969 - val_loss: 0.4990 - val_accuracy: 0.7969\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4216 - accuracy: 0.7986 - val_loss: 0.4990 - val_accuracy: 0.7969\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.7969 - val_loss: 0.4990 - val_accuracy: 0.7969\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7969 - val_loss: 0.4991 - val_accuracy: 0.7969\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.7969 - val_loss: 0.4991 - val_accuracy: 0.7969\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.7969 - val_loss: 0.4991 - val_accuracy: 0.7969\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7986 - val_loss: 0.4991 - val_accuracy: 0.7969\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.4991 - val_accuracy: 0.7969\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.4991 - val_accuracy: 0.7969\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.4991 - val_accuracy: 0.7969\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.4992 - val_accuracy: 0.7969\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.4992 - val_accuracy: 0.7969\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.4992 - val_accuracy: 0.7969\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.4992 - val_accuracy: 0.7969\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.4992 - val_accuracy: 0.7969\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.4992 - val_accuracy: 0.7969\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.4992 - val_accuracy: 0.7969\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7969 - val_loss: 0.4993 - val_accuracy: 0.7969\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.4993 - val_accuracy: 0.7969\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.4993 - val_accuracy: 0.7969\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.4993 - val_accuracy: 0.7969\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.4993 - val_accuracy: 0.7969\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4212 - accuracy: 0.7969 - val_loss: 0.4993 - val_accuracy: 0.7969\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.4993 - val_accuracy: 0.7969\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.4994 - val_accuracy: 0.7969\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.4994 - val_accuracy: 0.7969\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.4994 - val_accuracy: 0.7969\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.4994 - val_accuracy: 0.7969\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.4994 - val_accuracy: 0.7969\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.4994 - val_accuracy: 0.7969\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.4994 - val_accuracy: 0.7969\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.4994 - val_accuracy: 0.7969\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.4995 - val_accuracy: 0.7969\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.4995 - val_accuracy: 0.7969\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.4995 - val_accuracy: 0.7969\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.4995 - val_accuracy: 0.7969\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.4995 - val_accuracy: 0.7969\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7986 - val_loss: 0.4995 - val_accuracy: 0.7969\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.4995 - val_accuracy: 0.7969\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.4995 - val_accuracy: 0.7969\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.4995 - val_accuracy: 0.7969\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7986 - val_loss: 0.4995 - val_accuracy: 0.7969\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.4995 - val_accuracy: 0.7969\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.4995 - val_accuracy: 0.7969\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7951 - val_loss: 0.4996 - val_accuracy: 0.7969\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.4996 - val_accuracy: 0.7969\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.4996 - val_accuracy: 0.7969\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4996 - val_accuracy: 0.7917\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4996 - val_accuracy: 0.7917\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4996 - val_accuracy: 0.7917\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4996 - val_accuracy: 0.7917\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7951 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.4997 - val_accuracy: 0.7917\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7951 - val_loss: 0.4998 - val_accuracy: 0.7917\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7951 - val_loss: 0.4999 - val_accuracy: 0.7917\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.4999 - val_accuracy: 0.7917\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7951 - val_loss: 0.4999 - val_accuracy: 0.7917\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7951 - val_loss: 0.4999 - val_accuracy: 0.7917\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7951 - val_loss: 0.4999 - val_accuracy: 0.7917\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7951 - val_loss: 0.4999 - val_accuracy: 0.7917\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.4999 - val_accuracy: 0.7917\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.4999 - val_accuracy: 0.7917\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.4999 - val_accuracy: 0.7917\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5000 - val_accuracy: 0.7917\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5000 - val_accuracy: 0.7917\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5000 - val_accuracy: 0.7917\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5000 - val_accuracy: 0.7917\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5000 - val_accuracy: 0.7917\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5000 - val_accuracy: 0.7917\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5001 - val_accuracy: 0.7917\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7951 - val_loss: 0.5001 - val_accuracy: 0.7917\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5001 - val_accuracy: 0.7917\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.5001 - val_accuracy: 0.7917\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.5001 - val_accuracy: 0.7917\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7951 - val_loss: 0.5001 - val_accuracy: 0.7917\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.5001 - val_accuracy: 0.7917\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.5001 - val_accuracy: 0.7917\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.5001 - val_accuracy: 0.7917\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.5001 - val_accuracy: 0.7917\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.5001 - val_accuracy: 0.7917\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.5001 - val_accuracy: 0.7917\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.5002 - val_accuracy: 0.7917\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.5002 - val_accuracy: 0.7917\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.5002 - val_accuracy: 0.7917\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.5002 - val_accuracy: 0.7917\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4196 - accuracy: 0.7951 - val_loss: 0.5002 - val_accuracy: 0.7917\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5002 - val_accuracy: 0.7917\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7951 - val_loss: 0.5002 - val_accuracy: 0.7917\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7951 - val_loss: 0.5002 - val_accuracy: 0.7917\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7951 - val_loss: 0.5002 - val_accuracy: 0.7917\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7951 - val_loss: 0.5002 - val_accuracy: 0.7917\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.5003 - val_accuracy: 0.7917\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.5003 - val_accuracy: 0.7917\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.5003 - val_accuracy: 0.7917\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.5003 - val_accuracy: 0.7917\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.5003 - val_accuracy: 0.7917\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5003 - val_accuracy: 0.7917\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5003 - val_accuracy: 0.7917\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5003 - val_accuracy: 0.7917\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7951 - val_loss: 0.5003 - val_accuracy: 0.7917\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5004 - val_accuracy: 0.7917\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5004 - val_accuracy: 0.7917\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5004 - val_accuracy: 0.7917\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5004 - val_accuracy: 0.7917\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.5004 - val_accuracy: 0.7917\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5004 - val_accuracy: 0.7917\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5004 - val_accuracy: 0.7917\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5004 - val_accuracy: 0.7917\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5004 - val_accuracy: 0.7917\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5005 - val_accuracy: 0.7917\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5005 - val_accuracy: 0.7917\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5005 - val_accuracy: 0.7917\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.5005 - val_accuracy: 0.7917\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.5005 - val_accuracy: 0.7917\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5005 - val_accuracy: 0.7917\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.5005 - val_accuracy: 0.7917\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.7934 - val_loss: 0.5005 - val_accuracy: 0.7917\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5005 - val_accuracy: 0.7917\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5005 - val_accuracy: 0.7917\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5006 - val_accuracy: 0.7917\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21bddbeebe0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">---------------------------------------------------------------------------------------------</span>\n",
    "#### <span style=\"color:red\">RESPOSTA</span>\n",
    "\n",
    "O número apropriado de épocas é aquela anterior ao momento em que ocorre um incremento nos valores de perda (loss).\n",
    "É possível utilizar a callback earlystopping para tal ou olhar os logs.\n",
    "https://keras.io/api/callbacks/early_stopping/\n",
    "\n",
    "<span style=\"color:red\">---------------------------------------------------------------------------------------------</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"loss\", mode =\"min\", patience = 5, restore_best_weights = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5006 - val_accuracy: 0.7917\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5006 - val_accuracy: 0.7917\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5006 - val_accuracy: 0.7917\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5006 - val_accuracy: 0.7917\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7934 - val_loss: 0.5006 - val_accuracy: 0.7917\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7934 - val_loss: 0.5006 - val_accuracy: 0.7917\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7934 - val_loss: 0.5006 - val_accuracy: 0.7917\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7934 - val_loss: 0.5006 - val_accuracy: 0.7917\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7934 - val_loss: 0.5006 - val_accuracy: 0.7917\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7934 - val_loss: 0.5007 - val_accuracy: 0.7917\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7934 - val_loss: 0.5007 - val_accuracy: 0.7917\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7934 - val_loss: 0.5007 - val_accuracy: 0.7917\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7934 - val_loss: 0.5007 - val_accuracy: 0.7917\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7917 - val_loss: 0.5007 - val_accuracy: 0.7917\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7934 - val_loss: 0.5007 - val_accuracy: 0.7917\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7917 - val_loss: 0.5007 - val_accuracy: 0.7917\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7934 - val_loss: 0.5007 - val_accuracy: 0.7917\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7934 - val_loss: 0.5007 - val_accuracy: 0.7917\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7934 - val_loss: 0.5007 - val_accuracy: 0.7917\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.7934 - val_loss: 0.5007 - val_accuracy: 0.7917\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7934 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7934 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7917 - val_loss: 0.5009 - val_accuracy: 0.7917\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7917\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7917\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7917\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7917\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7917\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7917\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7917\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7917\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7917 - val_loss: 0.5010 - val_accuracy: 0.7865\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7934 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7934 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7934 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7934 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7934 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7934 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7917 - val_loss: 0.5011 - val_accuracy: 0.7865\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7934 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7934 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7934 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7934 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7951 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7934 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7934 - val_loss: 0.5012 - val_accuracy: 0.7865\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7951 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.7951 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7951 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5013 - val_accuracy: 0.7865\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7951 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7951 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7951 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7969 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7969 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7969 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7969 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7969 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7986 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7986 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7986 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7986 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7986 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.7986 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7986 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7986 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7986 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7986 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7986 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.7986 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7986 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7986 - val_loss: 0.5021 - val_accuracy: 0.7865\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7986 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7986 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7986 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5021 - val_accuracy: 0.7812\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7986 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7986 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7986 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7986 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7986 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.7986 - val_loss: 0.5022 - val_accuracy: 0.7812\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7812\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.7986 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7986 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7986 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7986 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7986 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.7986 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.7986 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.7986 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7986 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7986 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.7986 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7986 - val_loss: 0.5024 - val_accuracy: 0.7812\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7986 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7986 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7986 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7986 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.7986 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.7986 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.7986 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.7986 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.7986 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.7986 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.7986 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.7986 - val_loss: 0.5025 - val_accuracy: 0.7812\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7760\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7760\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.7986 - val_loss: 0.5026 - val_accuracy: 0.7760\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7986 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7986 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.7986 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7986 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7986 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7986 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.7986 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7986 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7986 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7986 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7986 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.7986 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.7986 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.7986 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7986 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7986 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7986 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7986 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.7986 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7986 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.5100 - accuracy: 0.75 - 0s 1ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7986 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.7986 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.7986 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7986 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7986 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7986 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7986 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7986 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.7986 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.7986 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7986 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7986 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7986 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7986 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.7986 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4127 - accuracy: 0.7986 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7986 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7986 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7986 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7986 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7986 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7986 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7986 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7986 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7986 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7986 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7986 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7986 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7986 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7986 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7986 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7986 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.84 - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7986 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7986 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7986 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.7986 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7986 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7986 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7986 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7986 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7986 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7986 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7986 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.7986 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.7986 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.7986 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.7986 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.7986 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.7986 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.7986 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.7986 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.7986 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.7986 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.7986 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.7986 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.7986 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.7986 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4117 - accuracy: 0.7986 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.7986 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.7986 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.7986 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.7986 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.7986 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.7986 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.7986 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.7986 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.7986 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4115 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4114 - accuracy: 0.7986 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7969 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7986 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4112 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.7969 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4112 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.7969 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.7986 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.7986 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.7969 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4110 - accuracy: 0.7969 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.7969 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.7986 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.7986 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.7986 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4110 - accuracy: 0.7986 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.7969 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.7986 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.7986 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.7986 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.7969 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.7969 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.7969 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.7969 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.7986 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.7969 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.7969 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.7969 - val_loss: 0.5053 - val_accuracy: 0.7656\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2976 - accuracy: 0.87 - 0s 1ms/step - loss: 0.4104 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7656\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4102 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7604\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7604\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7604\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7604\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7604\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7604\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7604\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4100 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.7951 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.7986 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.7986 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.7986 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.7986 - val_loss: 0.5064 - val_accuracy: 0.7604\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7604\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7604\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.7986 - val_loss: 0.5064 - val_accuracy: 0.7604\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.7986 - val_loss: 0.5064 - val_accuracy: 0.7604\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7604\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4098 - accuracy: 0.7986 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8003 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8003 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.7986 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8003 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8003 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8003 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8003 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8003 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8003 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8021 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8021 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8021 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4095 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8021 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.7986 - val_loss: 0.5068 - val_accuracy: 0.7604\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7604\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.7986 - val_loss: 0.5069 - val_accuracy: 0.7604\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8021 - val_loss: 0.5069 - val_accuracy: 0.7604\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7604\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8021 - val_loss: 0.5069 - val_accuracy: 0.7604\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7604\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7604\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8021 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8021 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8021 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8021 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4093 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8021 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8021 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8021 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8021 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8021 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4090 - accuracy: 0.8021 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8021 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8021 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4089 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8021 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8021 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4087 - accuracy: 0.7986 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.7986 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.7986 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.7986 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7604\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4084 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4084 - accuracy: 0.7986 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.7986 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.7986 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.7986 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.7986 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.7986 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.7986 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8003 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.7986 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4083 - accuracy: 0.7986 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.7986 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.7986 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.7986 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8003 - val_loss: 0.5084 - val_accuracy: 0.7604\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.7986 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4083 - accuracy: 0.7986 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8003 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8003 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.7986 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.8003 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8003 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.7986 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8003 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8003 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8003 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.8003 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4081 - accuracy: 0.8003 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8003 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8003 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8003 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8021 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8003 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8021 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.8021 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8003 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4080 - accuracy: 0.8021 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8003 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8021 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4079 - accuracy: 0.8021 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8003 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8003 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8021 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8038 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8021 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8038 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8003 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8021 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8003 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4078 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8003 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8003 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8038 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8038 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8038 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8038 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8038 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8038 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8021 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8021 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4075 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8038 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8056 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4072 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8056 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8038 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4070 - accuracy: 0.8056 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8056 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8038 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8038 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8038 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8038 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8056 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8038 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8038 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8038 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8038 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8038 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8038 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8038 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8038 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8021 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8038 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8038 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4068 - accuracy: 0.8056 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8021 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8056 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8056 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8038 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8056 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4068 - accuracy: 0.8056 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8038 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8038 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8038 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8056 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8038 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8056 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8056 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8056 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8056 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8056 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8021 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8038 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8038 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8038 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8038 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8056 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8038 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8038 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8038 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8038 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4065 - accuracy: 0.8056 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8038 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8038 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8038 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8056 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8056 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8056 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8056 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8038 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8056 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8038 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.8021 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8056 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8038 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8038 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8038 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8056 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.8056 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8056 - val_loss: 0.5097 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "run_hist_1NEW = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000, callbacks =[earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Now it's your turn.  Do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
